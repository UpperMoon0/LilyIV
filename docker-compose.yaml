# LilyIV Ecosystem Docker Compose Configuration
name: lily

services:
  # Lily-Core Application - Main chatbot service (C++)
  lily-core:
    image: nstut/lily-core
    build: ./Lily-Core
    ports:
      - "8000:8000"
      - "9002:9002"
    env_file:
      - ./Lily-Core/.env
    depends_on:
      web-scout:
        condition: service_started
      tts-provider:
        condition: service_started
      consul:
        condition: service_healthy
    networks:
      - lily-network
    environment:
      - CONSUL_HTTP_ADDR=consul:8500
    restart: unless-stopped

  # Web-Scout Application - Web search and MCP server
  web-scout:
    image: nstut/web-scout
    build: ./Web-Scout
    ports:
      - "8001:8000"
    env_file:
      - ./Lily-Core/.env
    environment:
      - PORT=8000
      - PYTHONPATH=/app/Web-Scout
      - DEBUG=${DEBUG:-false}
      - CONSUL_HTTP_ADDR=consul:8500
    networks:
      - lily-network
    depends_on:
      consul:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - web-scout-data:/app/data

  # TTS-Provider Application - Text-to-Speech generation service
  tts-provider:
    image: nstut/tts-provider
    build: ./TTS-Provider
    ports:
      - "8002:9000"
    env_file:
      - ./Web-Scout/.env
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - DEBUG=${DEBUG:-false}
      - CONSUL_HTTP_ADDR=consul:8500
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    depends_on:
      consul:
        condition: service_healthy
    networks:
      - lily-network
    restart: unless-stopped
    volumes:
      - tts-provider-hf-cache:/app/huggingface_cache

  # Echo Application - Speech-to-Text service with Whisper
  echo:
    image: nstut/echo
    build: ./Echo
    ports:
      - "8003:8000"
    env_file:
      - ./Echo/.env
    environment:
      - PYTHONUNBUFFERED=1
      - PORT=8000
      - PYTHONPATH=/app/Echo
      - DEBUG=${DEBUG:-false}
      - CONSUL_HTTP_ADDR=consul:8500
    depends_on:
      consul:
        condition: service_healthy
    networks:
      - lily-network
    restart: unless-stopped
    volumes:
      - echo-data:/app/data

  # Lily-Discord-Adapter - Discord bot adapter for Lily-Core
  lily-discord-adapter:
    image: nstut/lily-discord-adapter
    build: ./Lily-Discord-Adapter
    ports:
      - "8004:8004"
    env_file:
      - ./Lily-Discord-Adapter/.env
    environment:
      - PYTHONUNBUFFERED=1
      - PORT=8004
      - PYTHONPATH=/app/Lily-Discord-Adapter
      - CONSUL_HTTP_ADDR=consul:8500
      - YOUTUBE_COOKIES_FILE=/app/Lily-Discord-Adapter/cookies.txt
    depends_on:
      lily-core:
        condition: service_started
      consul:
        condition: service_healthy
    networks:
      - lily-network
    restart: unless-stopped
    volumes:
      - lily-discord-adapter-data:/app/data
      - ./Lily-Discord-Adapter/cookies.txt:/app/Lily-Discord-Adapter/cookies.txt

  # E2E Test Runner - Runs Python script to test speech flow
  e2e-test:
    build:
      context: .
      dockerfile: tests/Dockerfile
    profiles: [ "test" ]
    depends_on:
      - lily-core
      - echo
    networks:
      - lily-network

  # Consul - Service Registry
  consul:
    image: hashicorp/consul:latest
    ports:
      - "8500:8500"
      - "8600:8600/udp"
    networks:
      - lily-network
    command: "agent -dev -client '0.0.0.0'"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/v1/status/leader"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

networks:
  lily-network:
    driver: bridge

volumes:
  # Data persistence for Web-Scout
  web-scout-data:
    driver: local
  # HuggingFace cache persistence for TTS-Provider
  tts-provider-hf-cache:
    driver: local
  # Data persistence for Echo
  echo-data:
    driver: local
  # Data persistence for Lily-Discord-Adapter
  lily-discord-adapter-data:
    driver: local
